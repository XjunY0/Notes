## 损失函数的使用

损失函数（或称目标函数、优化评分函数）是编译模型时所需的两个参数之一：

```
model.compile(loss='mean_squared_error', optimizer='sgd')
```

```
from keras import losses

model.compile(loss=losses.mean_squared_error, optimizer='sgd')
```

你可以传递一个现有的损失函数名，或者一个 TensorFlow/Theano 符号函数。 该符号函数为每个数据点返回一个标量，有以下两个参数:

-   **y_true**: 真实标签。TensorFlow/Theano 张量。
-   **y_pred**: 预测值。TensorFlow/Theano 张量，其 shape 与 y_true 相同。

实际的优化目标是所有数据点的输出数组的平均值。

有关这些函数的几个例子，请查看 [losses source](https://github.com/keras-team/keras/blob/master/keras/losses.py)。

## 可用损失函数

### mean_squared_error

```
keras.losses.mean_squared_error(y_true, y_pred)
```

----------

### mean_absolute_error

```
keras.losses.mean_absolute_error(y_true, y_pred)
```

----------

### mean_absolute_percentage_error

```
keras.losses.mean_absolute_percentage_error(y_true, y_pred)
```

----------

### mean_squared_logarithmic_error

```
keras.losses.mean_squared_logarithmic_error(y_true, y_pred)
```

----------

### squared_hinge

```
keras.losses.squared_hinge(y_true, y_pred)
```

----------

### hinge

```
keras.losses.hinge(y_true, y_pred)
```

----------

### categorical_hinge

```
keras.losses.categorical_hinge(y_true, y_pred)
```

----------

### logcosh

```
keras.losses.logcosh(y_true, y_pred)
```

预测误差的双曲余弦的对数。

对于小的 `x`，`log(cosh(x))` 近似等于 `(x ** 2) / 2`。对于大的 `x`，近似于 `abs(x) - log(2)`。这表示 'logcosh' 与均方误差大致相同，但是不会受到偶尔疯狂的错误预测的强烈影响。

**参数**

-   **y_true**: 目标真实值的张量。
-   **y_pred**: 目标预测值的张量。

**返回**

每个样本都有一个标量损失的张量。

----------

### huber_loss

```
keras.losses.huber_loss(y_true, y_pred, delta=1.0)
```

----------

### categorical_crossentropy

```
keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0)
```

----------

### sparse_categorical_crossentropy

```
keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1)
```

----------

### binary_crossentropy

```
keras.losses.binary_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0)
```

----------

### kullback_leibler_divergence

```
keras.losses.kullback_leibler_divergence(y_true, y_pred)
```

----------

### poisson

```
keras.losses.poisson(y_true, y_pred)
```

----------

### cosine_proximity

```
keras.losses.cosine_proximity(y_true, y_pred, axis=-1)
```

----------

### is_categorical_crossentropy

```
keras.losses.is_categorical_crossentropy(loss)
```

----------

**注意**: 当使用 `categorical_crossentropy` 损失时，你的目标值应该是分类格式 (即，如果你有 10 个类，每个样本的目标值应该是一个 10 维的向量，这个向量除了表示类别的那个索引为 1，其他均为 0)。 为了将 _整数目标值_ 转换为 _分类目标值_，你可以使用 Keras 实用函数 `to_categorical`：

```
from keras.utils.np_utils import to_categorical

categorical_labels = to_categorical(int_labels, num_classes=None)
```

当使用 sparse_categorical_crossentropy 损失时，你的目标应该是整数。如果你是类别目标，应该使用 categorical_crossentropy。

categorical_crossentropy 是多类对数损失的另一种形式。

### 回归任务的损失函数

1.  **Mean Squared Error (MSE)**
    
    -   **函数**：`keras.losses.mean_squared_error(y_true, y_pred)`
    -   **用途**：常用于回归问题，适合处理具有正态分布的误差。
    -   **特点**：对大误差较为敏感，因为误差被平方放大。
2.  **Mean Absolute Error (MAE)**
    
    -   **函数**：`keras.losses.mean_absolute_error(y_true, y_pred)`
    -   **用途**：常用于回归问题，对异常值不太敏感。
    -   **特点**：度量预测值和真实值之间的绝对差异，能更稳健地处理异常值。
3.  **Mean Absolute Percentage Error (MAPE)**
    
    -   **函数**：`keras.losses.mean_absolute_percentage_error(y_true, y_pred)`
    -   **用途**：用于回归问题，当希望误差度量为相对百分比时。
    -   **特点**：计算预测值和真实值之间的百分比误差，适合处理比例误差。
4.  **Mean Squared Logarithmic Error (MSLE)**
    
    -   **函数**：`keras.losses.mean_squared_logarithmic_error(y_true, y_pred)`
    -   **用途**：用于回归问题，尤其是目标值范围较大且差异显著的情况下。
    -   **特点**：对预测值的对数进行平方误差计算，适合处理增长率数据。
5.  **Huber Loss**
    
    -   **函数**：`keras.losses.huber_loss(y_true, y_pred, delta=1.0)`
    -   **用途**：结合了 MSE 和 MAE 的优点，常用于回归问题。
    -   **特点**：在误差较小时类似于 MSE，误差较大时类似于 MAE，更加稳健。
6.  **Log-Cosh Loss**
    
    -   **函数**：`keras.losses.logcosh(y_true, y_pred)`
    -   **用途**：用于回归问题，结合了 MSE 的优点且对异常值不太敏感。
    -   **特点**：计算预测误差的双曲余弦的对数，稳定且适中。

### 分类任务的损失函数

1.  **Categorical Crossentropy**
    
    -   **函数**：`keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0)`
    -   **用途**：用于多类分类问题，目标值为 one-hot 编码。
    -   **特点**：度量分类预测与真实标签之间的交叉熵损失。
2.  **Sparse Categorical Crossentropy**
    
    -   **函数**：`keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1)`
    -   **用途**：用于多类分类问题，目标值为整数标签。
    -   **特点**：与 categorical_crossentropy 类似，但目标值为整数形式。
3.  **Binary Crossentropy**
    
    -   **函数**：`keras.losses.binary_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0)`
    -   **用途**：用于二分类问题。
    -   **特点**：度量二分类预测与真实标签之间的交叉熵损失。
4.  **Kullback-Leibler Divergence (KL Divergence)**
    
    -   **函数**：`keras.losses.kullback_leibler_divergence(y_true, y_pred)`
    -   **用途**：用于衡量两个概率分布之间的差异。
    -   **特点**：常用于信息论和概率分布的建模问题。
5.  **Poisson Loss**
    
    -   **函数**：`keras.losses.poisson(y_true, y_pred)`
    -   **用途**：用于泊松分布建模问题，如事件发生次数的预测。
    -   **特点**：计算预测值和真实值之间的泊松分布误差。
6.  **Cosine Proximity**
    
    -   **函数**：`keras.losses.cosine_proximity(y_true, y_pred, axis=-1)`
    -   **用途**：用于度量两个向量之间的余弦相似度，常用于文本相似度和推荐系统。
    -   **特点**：计算预测值和真实值之间的余弦相似度，衡量向量方向的一致性。

### 二分类任务的损失函数

1.  **Squared Hinge**
    
    -   **函数**：`keras.losses.squared_hinge(y_true, y_pred)`
    -   **用途**：用于二分类问题，特别是支持向量机（SVM）。
    -   **特点**：计算平方的 hinge 损失，对错误分类的惩罚更大。
2.  **Hinge**
    
    -   **函数**：`keras.losses.hinge(y_true, y_pred)`
    -   **用途**：用于二分类问题，特别是支持向量机（SVM）。
    -   **特点**：计算 hinge 损失，对错误分类进行线性惩罚。
3.  **Categorical Hinge**
    
    -   **函数**：`keras.losses.categorical_hinge(y_true, y_pred)`
    -   **用途**：用于多类分类问题，类似于 SVM 的多分类问题。
    -   **特点**：计算多类 hinge 损失。

### 选择损失函数的总结

-   **回归问题**：MSE、MAE、MSLE、Huber Loss、Log-Cosh Loss。
-   **二分类问题**：Binary Crossentropy、Hinge、Squared Hinge。
-   **多类分类问题**：Categorical Crossentropy、Sparse Categorical Crossentropy、Categorical Hinge。
-   **概率分布建模**：KL Divergence、Poisson Loss。
-   **向量相似度**：Cosine Proximity。

选择合适的损失函数取决于你的具体任务和数据特征。回归问题通常使用 MSE 或 MAE；分类问题根据是二分类还是多分类，选择 Binary Crossentropy 或 Categorical Crossentropy；对于处理概率分布的任务，使用 KL Divergence；对于向量相似度的计算，可以使用 Cosine Proximity。
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTY1MzU0NjE2MywxNDAwNzY4MDU4XX0=
-->