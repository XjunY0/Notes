## onnx

`onnx`（Open Neural Network Exchange）是一个开放格式，用于机器学习模型的跨框架互操作性。使用 `onnx`，你可以在不同的深度学习框架之间导出和导入模型。

下面是一些常见的 `onnx` 用法示例，包括如何安装 `onnx` 和相关库，如何导出模型到 `onnx` 格式，以及如何加载和使用 `onnx` 模型。

### 将Pytorch模型导出为 `onnx` 格式

假设我们使用 PyTorch 训练了一个简单的模型，现在我们将其导出为 `onnx` 格式。
~~~py
import torch
import torch.nn as nn
import torch.onnx

# 定义一个简单的模型
class SimpleModel(nn.Module):
    def __init__(self):
        super(SimpleModel, self).__init__()
        self.fc = nn.Linear(10, 5)

    def forward(self, x):
        return self.fc(x)

# 初始化模型并生成一个输入张量
model = SimpleModel()
dummy_input = torch.randn(1, 10)

# 导出模型到 onnx 格式
torch.onnx.export(model, dummy_input, "simple_model.onnx", verbose=True)
~~~

~~~py
torch.onnx.export(model, args, f, export_params=True, verbose=False, training=torch.onnx.TrainingMode.EVAL, input_names=None, output_names=None, operator_export_type=None, opset_version=None, do_constant_folding=True, dynamic_axes=None, keep_initializers_as_inputs=None, custom_opsets=None, enable_onnx_checker=True, use_external_data_format=False, onnx_shape_inference=False)
~~~

#### 参数说明

-   `model`：要导出的 PyTorch 模型。
-   `args`：模型的输入张量，或输入张量的元组。
-   `f`：要保存的文件名或文件对象。
-   `export_params`：是否导出模型参数。默认为 `True`。
-   `verbose`：是否打印导出过程的详细信息。默认为 `False`。
-   `training`：导出模型的模式，可以是 `TrainingMode.EVAL`（评估模式）或 `TrainingMode.TRAINING`（训练模式）。
-   `input_names`：输入节点的名称列表。
-   `output_names`：输出节点的名称列表。
-   `operator_export_type`：导出类型。
-   `opset_version`：导出的 ONNX opset 版本。
-   `do_constant_folding`：是否执行常量折叠优化。默认为 `True`。
-   `dynamic_axes`：动态轴的定义，用于支持可变长度输入。
-   `keep_initializers_as_inputs`：是否将初始化器保留为输入。默认为 `None`。
-   `custom_opsets`：自定义 opset 版本。
-   `enable_onnx_checker`：是否启用 ONNX 检查器。默认为 `True`。
-   `use_external_data_format`：是否使用外部数据格式。默认为 `False`。
-   `onnx_shape_inference`：是否在导出时执行 ONNX 形状推理。默认为 `False`。

### 加载和运行 `onnx` 模型

使用 `onnxruntime` 加载和运行 `onnx` 模型。
~~~py
import onnxruntime as ort
import numpy as np

# 加载 onnx 模型
ort_session = ort.InferenceSession("simple_model.onnx")

# 创建输入数据
input_data = np.random.randn(1, 10).astype(np.float32)

# 运行模型
outputs = ort_session.run(None, {"input.1": input_data})
print(outputs)
~~~

### 验证 `onnx` 模型

使用 `onnx` 库来验证模型的结构和正确性。
~~~py
import onnx

# 加载 onnx 模型
model = onnx.load("simple_model.onnx")

# 检查模型是否有效
onnx.checker.check_model(model)

# 打印模型的图形信息
print(onnx.helper.printable_graph(model.graph))
~~~

### 将其他框架的模型转换为 `onnx`

许多深度学习框架都支持将模型导出为 `onnx` 格式。例如，将 TensorFlow 模型导出为 `onnx`：
~~~py
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import tf2onnx

# 定义一个简单的模型
model = Sequential([Dense(5, input_shape=(10,), activation='relu')])

# 将模型保存为 SavedModel 格式
model.save("simple_model")

# 将 SavedModel 转换为 onnx 格式
!python -m tf2onnx.convert --saved-model simple_model --output simple_model.onnx
~~~
### 将 `onnx` 模型导回其他框架

将 `onnx` 模型导回 PyTorch：
~~~py
import torch
import onnx
import onnx2pytorch

# 加载 onnx 模型
onnx_model = onnx.load("simple_model.onnx")

# 将 onnx 模型转换为 PyTorch 模型
pytorch_model = onnx2pytorch.ConvertModel(onnx_model)
~~~

### 常见操作总结

1.  **安装和导入**：
    
~~~bash
pip install onnx onnxruntime
~~~
    
2.  **导出模型到 `onnx`**：
    
~~~py
import torch.onnx 
torch.onnx.export(model, dummy_input, "model.onnx")
~~~
3.  **加载和运行 `onnx` 模型**：
    
~~~py
import onnxruntime as ort 
ort_session = ort.InferenceSession("model.onnx") outputs = 
ort_session.run(None, {"input": input_data})
~~~
4.  **验证 `onnx` 模型**：
~~~py
import onnx 
onnx_model = onnx.load("model.onnx") 
onnx.checker.check_model(onnx_model)`
~~~
5.  **转换其他框架模型到 `onnx`**：
~~~bash
python -m tf2onnx.convert --saved-model saved_model_dir --output model.onnx
~~~

通过上述示例和操作步骤，你可以熟练掌握 `onnx` 的常见用法，从而在不同深度学习框架之间进行模型的无缝转换和部署。
<!--stackedit_data:
eyJoaXN0b3J5IjpbNTAwMTY0NTYsLTE4MjIyOTQzNzddfQ==
-->