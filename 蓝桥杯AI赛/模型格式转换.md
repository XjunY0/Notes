## onnx

`onnx`（Open Neural Network Exchange）是一个开放格式，用于机器学习模型的跨框架互操作性。使用 `onnx`，你可以在不同的深度学习框架之间导出和导入模型。

下面是一些常见的 `onnx` 用法示例，包括如何安装 `onnx` 和相关库，如何导出模型到 `onnx` 格式，以及如何加载和使用 `onnx` 模型。

### 将Pytorch模型导出为 `onnx` 格式

假设我们使用 PyTorch 训练了一个简单的模型，现在我们将其导出为 `onnx` 格式。
~~~py
import torch
import torch.nn as nn
import torch.onnx

# 定义一个简单的模型
class SimpleModel(nn.Module):
    def __init__(self):
        super(SimpleModel, self).__init__()
        self.fc = nn.Linear(10, 5)

    def forward(self, x):
        return self.fc(x)

# 初始化模型并生成一个输入张量
model = SimpleModel()
dummy_input = torch.randn(1, 10)

# 导出模型到 onnx 格式
torch.onnx.export(model, dummy_input, "simple_model.onnx", verbose=True)
~~~

`torch.onnx.export`(

### 加载和运行 `onnx` 模型

使用 `onnxruntime` 加载和运行 `onnx` 模型。
~~~py
import onnxruntime as ort
import numpy as np

# 加载 onnx 模型
ort_session = ort.InferenceSession("simple_model.onnx")

# 创建输入数据
input_data = np.random.randn(1, 10).astype(np.float32)

# 运行模型
outputs = ort_session.run(None, {"input.1": input_data})
print(outputs)
~~~
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTIwMDM3NzcxXX0=
-->